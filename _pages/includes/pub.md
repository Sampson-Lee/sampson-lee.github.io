
# üìù Publications 
## üòú Visual Emotion Recognition


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM-MM 2024</div><img src='images/dsct.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Two in One Go: Single-stage Emotion Recognition with Decoupled Subject-context Transformer](https://arxiv.org/pdf/2404.17205) \\
**Xinpeng Li**, Teng Wang, Jian Zhao, Shuyi Mao, Jinbao Wang, Feng Zheng, Xiaojiang Peng, Xuelong Li.

[**Project**](https://github.com/Sampson-Lee/DSCT) <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:u5HHmVD_uO8C'></span></strong>

- DSCT is a single-stage emotion recognition approach for simultaneous subject localization and emotion classification.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2024</div><img src='images/auvt.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Facial Action Units as A Bridge of Joint Dataset Training for Facial Expression Recognition](https://arxiv.org/pdf/2211.06609.pdf) \\
**Yi Ren**, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://github.com/msy1412/ABAW4) <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:2osOgNQ5qMEC'></span></strong>
  - AU-ViT improves the performance of a target dataset by jointly training auxiliary datasets with off-the-shelf or pseudo AU labels.
</div>
</div>

