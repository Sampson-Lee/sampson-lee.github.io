
# üìù Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint 2026</div><img src='images/omnimmsi.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Omni-MMSI: Towards Identity-aware Social Interaction Understanding.]() <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:u5HHmVD_uO8C'></span></strong> \\
**Xinpeng Li**, Bolin Lai, Hardy Chen, Shijian Deng, Cihang Xie, Yuyin Zhou, James M. Rehg, Yapeng Tian.

**Omni-MMSI-LLM**, addressing the identity attribution difficulty in directly operating on raw audio-video input, conduct reasoning to leverage references for identity-aware understanding and strengthen association with tools.
</div>
</div>
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2026</div><img src='images/onlinemmsi.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Towards Online Multi-Modal Social Interaction Understanding](https://openreview.net/pdf?id=5P7yVfUEuD) [![](https://img.shields.io/github/stars/Sampson-Lee/OnlineMMSI?style=social)](https://github.com/Sampson-Lee/OnlineMMSI) <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:u5HHmVD_uO8C'></span></strong> \\
**Xinpeng Li**, Shijian Deng, Bolin Lai, Weiguo Pian, James M. Rehg, Yapeng Tian.

**Online-MMSI-VLM** is a novel framework, for the newly proposed online MMSI setting, that leverages multi-party conversation forecasting and social-aware visual prompting with multimodal large language models.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM-MM 2024</div><img src='images/dsct.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Two in One Go: Single-stage Emotion Recognition with Decoupled Subject-context Transformer](https://arxiv.org/pdf/2404.17205) [![](https://img.shields.io/github/stars/Sampson-Lee/DSCT?style=social)](https://github.com/Sampson-Lee/DSCT) <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:u5HHmVD_uO8C'></span></strong> \\
**Xinpeng Li**, Teng Wang, Jian Zhao, Shuyi Mao, Jinbao Wang, Feng Zheng, Xiaojiang Peng, Xuelong Li.

**DSCT** is a single-stage emotion recognition approach, with subject-context decoupling, for simultaneous subject localization and emotion classification.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2024</div><img src='images/auvt.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Facial Action Units as a Joint Dataset Training Bridge for Facial Expression Recognition](https://arxiv.org/pdf/2211.06609.pdf) [![](https://img.shields.io/github/stars/msy1412/ABAW4?style=social)](https://github.com/msy1412/ABAW4) <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:2osOgNQ5qMEC'></span></strong>\\
Shuyi Mao, **Xinpeng Li**, Fan Zhang, Xiaojiang Peng, and Yang Yang.

**AU-ViT** improves the performance of a target dataset by jointly training auxiliary datasets with off-the-shelf or pseudo AU labels.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/real3d.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Real3D-AD: A Dataset of Point Cloud Anomaly Detection](https://arxiv.org/pdf/2309.13226.pdf) [![](https://img.shields.io/github/stars/M-3LAB/Real3D-AD?style=social)](https://github.com/M-3LAB/Real3D-AD) <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:d1gkVwhDpl0C'></span></strong>\\
Jiaqi Liu, Guoyang Xie, Ruitao Chen, **Xinpeng Li**, Jinbao Wang, Yong Liu, Chengjie Wang, Feng Zheng.

**Real3D-AD** is a new dataset and benchmark of high-resolution 3D point clouds for anomaly detection tasks in real-world scenes.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM-MM 2022</div><img src='images/raildb.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Rail Detection: An Efficient Row-based Network and a New Benchmark](https://arxiv.org/pdf/2304.05667.pdf) [![](https://img.shields.io/github/stars/Sampson-Lee/Rail-Detection?style=social)](https://github.com/Sampson-Lee/Rail-Detection) <strong><span class='show_paper_citations' data='59fdU3wAAAAJ:u-x6o8ySG0sC'></span></strong>\\
**Xinpeng Li**, and Xiaojiang Peng.

**Rail-Detection** includes Rail-DB and Rail-Net, a new real-world railway dataset and an efficient row-based rail detection method.
</div>
</div>
